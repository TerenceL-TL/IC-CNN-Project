{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN-based Brain Tumour Segmentation Network\n",
    "## Import packages\n",
    "Please make sure you have all the required packages installed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-11 19:13:47.799089: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-11 19:13:47.880353: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-11 19:13:49.149434: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-11 19:13:49.155154: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-11 19:13:49.173399: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-11 19:13:49.173615: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-11 19:13:49.258629: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-11 19:13:49.258799: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-11 19:13:49.258888: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-11 19:13:49.258967: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1167 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from matplotlib.widgets import Slider\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise MRI Volume Slices and Segmentation Maps\n",
    "Each MRI image contains information about a three-dimensional (3D) volume of space. An MRI image is composed of a number of voxels, which is like pixels in 2D images. Here try to visualise the axial plane (usually has a higher resolution) of some of the volumes and the corresponding segmentation maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d03c839958140a4826d72473007642d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Data Select', options=('Nothing Selected', '001', '002', '003', '004', '005', '006', '00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92801dab0a434ab2ac8c9d68cc91d675",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='val', max=154), Output()), _dom_classes=('widget-interac…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30f2c4a9951c411fbe4696d25886f55b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='val', max=154), Output()), _dom_classes=('widget-interac…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data Visualization\n",
    "# Choose set on the selection bar, then use the trackbar for moving up and down\n",
    "\n",
    "# messages\n",
    "no_selection_hint = \"Nothing Selected\"\n",
    "\n",
    "# path related\n",
    "img_path = 'dataset_segmentation/'\n",
    "train_path = os.path.join(img_path, \"train\")\n",
    "\n",
    "\n",
    "# global variables \n",
    "view_pla_path = None\n",
    "view_seg_path = None\n",
    "view_pla_load = None\n",
    "view_seg_load = None\n",
    "slices = None\n",
    "sliders = None\n",
    "\n",
    "def update_slice(val):\n",
    "    global view_pla_load\n",
    "    global view_seg_load\n",
    "    imgfla = view_pla_load[:,:,val]\n",
    "    imgseg = view_seg_load[:,:,val]\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(imgfla, cmap='gray')\n",
    "    plt.title('FLA')\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(imgseg, cmap='gray')\n",
    "    plt.title('SEG')\n",
    "    plt.show()\n",
    "    return()\n",
    "\n",
    "def update_set(strval):\n",
    "    global view_pla_path \n",
    "    global view_seg_path\n",
    "    global view_pla_load\n",
    "    global view_seg_load\n",
    "    global slices\n",
    "    global sliders\n",
    "    try:\n",
    "        if sliders is not None:\n",
    "            sliders.close()\n",
    "    except NameError:\n",
    "        pass\n",
    "    if strval['type'] == 'change' and strval['name'] == 'value':\n",
    "        set_str = strval['new']\n",
    "    # print(set_str)\n",
    "    if set_str == no_selection_hint:\n",
    "        return()\n",
    "    view_pla_path = os.path.join(train_path, set_str, set_str + \"_fla.nii.gz\")\n",
    "    view_seg_path = os.path.join(train_path, set_str, set_str + \"_seg.nii.gz\")\n",
    "\n",
    "    view_pla_load = nib.load(view_pla_path).get_fdata()\n",
    "    view_seg_load = nib.load(view_seg_path).get_fdata()\n",
    "\n",
    "    slices = view_pla_load.shape\n",
    "    sliders = interactive(update_slice, val=widgets.IntSlider(value=0, min=0, max=slices[2]-1, step=1) )\n",
    "    display(sliders)\n",
    "    return()\n",
    "\n",
    "dataset_subfolder = []\n",
    "\n",
    "for CLASS in os.listdir(train_path):\n",
    "    if not CLASS.startswith('.'):\n",
    "        dataset_subfolder.append(CLASS)\n",
    "\n",
    "dataset_subfolder.sort()\n",
    "dataset_subfolder.insert(0, no_selection_hint)\n",
    "\n",
    "dropdown = widgets.Dropdown(options=dataset_subfolder, value=no_selection_hint, description='Data Select')\n",
    "\n",
    "dropdown.observe(update_set, names='value')\n",
    "display(dropdown)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing (Optional)\n",
    "\n",
    "Images in the original dataset are usually in different sizes, so sometimes we need to resize and normalise (z-score is commonly used in preprocessing the MRI images) them to fit the CNN model. Depending on the images you choose to use for training your model, some other preprocessing methods. If preprocessing methods like cropping is applied, remember to convert the segmentation result back to its original size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-time data augmentation\n",
    "Generalizability is crucial to a deep learning model and it refers to the performance difference of a model when evaluated on the seen data (training data) versus the unseen data (testing data). Improving the generalizability of these models has always been a difficult challenge. \n",
    "\n",
    "**Data Augmentation** is an effective way of improving the generalizability, because the augmented data will represent a more comprehensive set of possible data samples and minimizing the distance between the training and validation/testing sets.\n",
    "\n",
    "There are many data augmentation methods you can choose in this projects including rotation, shifting, flipping, etc.\n",
    "\n",
    "You are encouraged to try different augmentation method to get the best segmentation result.\n",
    "\n",
    "\n",
    "## Get the data generator ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, batch_size=32, dim=(240,240), n_channels=3,\n",
    "                 n_classes=2, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y \n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            # Add data augmentation here\n",
    "            X[i,] = np.load(ID)\n",
    "\n",
    "            # Store class\n",
    "            y[i] = min(1,np.sum(np.load(ID.split('_')[0]+'_seg.npy')))\n",
    "\n",
    "        return X, tf.keras.utils.to_categorical(y, num_classes=self.n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a metric for the performance of the model\n",
    "Dice score is used here to evaluate the performance of your model.\n",
    "More details about the Dice score and other metrics can be found at \n",
    "https://towardsdatascience.com/metrics-to-evaluate-your-semantic-segmentation-model-6bcb99639aa2. Dice score can be also used as the loss function for training your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build your own model here\n",
    "The U-Net (https://link.springer.com/chapter/10.1007/978-3-319-24574-4_28) structure is widely used for the medical image segmentation task. You can build your own model or modify the UNet by changing the hyperparameters for our task. If you choose to use Keras, more information about the Keras layers including Conv2D, MaxPooling and Dropout can be found at https://keras.io/api/layers/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import itertools\n",
    " \n",
    "class UNet:\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_width,\n",
    "            input_height,\n",
    "            num_classes,\n",
    "            train_images,\n",
    "            train_instances,\n",
    "            val_images,\n",
    "            val_instances,\n",
    "            epochs,\n",
    "            lr,\n",
    "            lr_decay,\n",
    "            batch_size,\n",
    "            save_path\n",
    "    ):\n",
    "        self.input_width = input_width\n",
    "        self.input_height = input_height\n",
    "        self.num_classes = num_classes\n",
    "        self.train_images = train_images\n",
    "        self.train_instances = train_instances\n",
    "        self.val_images = val_images\n",
    "        self.val_instances = val_instances\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.lr_decay = lr_decay\n",
    "        self.batch_size = batch_size\n",
    "        self.save_path = save_path\n",
    " \n",
    "    def leftNetwork(self, inputs):\n",
    "        x = tf.keras.layers.Conv2D(64, (3, 3), padding='valid', activation='relu')(inputs)\n",
    "        o_1 = tf.keras.layers.Conv2D(64, (3, 3), padding='valid', activation='relu')(x)\n",
    "        x = tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2, 2))(o_1)\n",
    " \n",
    "        x = tf.keras.layers.Conv2D(128, (3, 3), padding='valid', activation='relu')(x)\n",
    "        o_2 = tf.keras.layers.Conv2D(128, (3, 3), padding='valid', activation='relu')(x)\n",
    "        x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(o_2)\n",
    " \n",
    "        x = tf.keras.layers.Conv2D(256, (3, 3), padding='valid', activation='relu')(x)\n",
    "        o_3 = tf.keras.layers.Conv2D(256, (3, 3), padding='valid', activation='relu')(x)\n",
    "        x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(o_3)\n",
    " \n",
    "        x = tf.keras.layers.Conv2D(512, (3, 3), padding='valid', activation='relu')(x)\n",
    "        o_4 = tf.keras.layers.Conv2D(512, (3, 3), padding='valid', activation='relu')(x)\n",
    "        x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(o_4)\n",
    " \n",
    "        x = tf.keras.layers.Conv2D(1024, (3, 3), padding='valid', activation='relu')(x)\n",
    "        o_5 = tf.keras.layers.Conv2D(1024, (3, 3), padding='valid', activation='relu')(x)\n",
    " \n",
    "        return [o_1, o_2, o_3, o_4, o_5]\n",
    " \n",
    "    def rightNetwork(self, inputs):\n",
    "        c_1, c_2, c_3, c_4, o_5 = inputs\n",
    " \n",
    "        o_5 = tf.keras.layers.UpSampling2D((2, 2))(o_5)\n",
    "        x = tf.keras.layers.concatenate([tf.keras.layers.Cropping2D(4)(c_4), o_5], axis=3)\n",
    "        x = tf.keras.layers.Conv2D(512, (3, 3), padding='valid', activation='relu')(x)\n",
    "        x = tf.keras.layers.Conv2D(512, (3, 3), padding='valid', activation='relu')(x)\n",
    "        x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
    " \n",
    "        x = tf.keras.layers.concatenate([tf.keras.layers.Cropping2D(16)(c_3), x], axis=3)\n",
    "        x = tf.keras.layers.Conv2D(256, (3, 3), padding='valid', activation='relu')(x)\n",
    "        x = tf.keras.layers.Conv2D(256, (3, 3), padding='valid', activation='relu')(x)\n",
    "        x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
    " \n",
    "        x = tf.keras.layers.concatenate([tf.keras.layers.Cropping2D(40)(c_2), x], axis=3)\n",
    "        x = tf.keras.layers.Conv2D(128, (3, 3), padding='valid', activation='relu')(x)\n",
    "        x = tf.keras.layers.Conv2D(128, (3, 3), padding='valid', activation='relu')(x)\n",
    "        x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
    " \n",
    "        x = tf.keras.layers.concatenate([tf.keras.layers.Cropping2D(88)(c_1), x], axis=3)\n",
    "        x = tf.keras.layers.Conv2D(64, (3, 3), padding='valid', activation='relu')(x)\n",
    "        x = tf.keras.layers.Conv2D(64, (3, 3), padding='valid', activation='relu')(x)\n",
    "        x = tf.keras.layers.Conv2D(self.num_classes, (1, 1), padding='valid')(x)\n",
    "        x = tf.keras.layers.Activation('softmax')(x)\n",
    " \n",
    "        return x\n",
    " \n",
    "    def build_model(self):\n",
    "        inputs = tf.keras.Input(shape=[self.input_height, self.input_width, 3])\n",
    "        left_output = self.leftNetwork(inputs)\n",
    "        right_output = self.rightNetwork(left_output)\n",
    "\n",
    "        model = tf.keras.Model(inputs=inputs, outputs=right_output)\n",
    " \n",
    "        return model\n",
    " \n",
    "    def train(self):\n",
    "        G_train = self.dataGenerator(model='training')\n",
    "        G_eval = self.dataGenerator(model='validation')\n",
    " \n",
    "        model = self.build_model()\n",
    "        # model = tf.keras.models.load_model('trained_model.h5')\n",
    "        print(\"Built\")\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(self.lr, self.lr_decay),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        model.fit_generator(\n",
    "            G_train, 5, validation_data=G_eval, validation_steps=5, epochs=self.epochs\n",
    "        )\n",
    "        model.save(self.save_path)\n",
    " \n",
    "    def dataGenerator(self, model):\n",
    "        if model == 'training':\n",
    "            images = glob.glob(self.train_images + '*.jpg')\n",
    "            images.sort()\n",
    "            instances = glob.glob(self.train_instances + '*.jpg')\n",
    "            instances.sort()\n",
    "            zipped = itertools.cycle(zip(images, instances))\n",
    "            while True:\n",
    "                x_train = []\n",
    "                y_train = []\n",
    "                for _ in range(self.batch_size):\n",
    "                    img, seg = next(zipped)\n",
    "                    img = cv2.resize(cv2.imread(img, 1), (self.input_width, self.input_height)) / 255.0\n",
    "                    seg = tf.keras.utils.to_categorical(cv2.imread(seg, 0), self.num_classes)\n",
    "                    x_train.append(img)\n",
    "                    y_train.append(seg)\n",
    " \n",
    "                yield np.array(x_train), np.array(y_train)\n",
    " \n",
    "        if model == 'validation':\n",
    "            images = glob.glob(self.val_images + '*.jpg')\n",
    "            images.sort()\n",
    "            instances = glob.glob(self.val_instances + '*.jpg')\n",
    "            instances.sort()\n",
    "            zipped = itertools.cycle(zip(images, instances))\n",
    " \n",
    "            while True:\n",
    "                x_eval = []\n",
    "                y_eval = []\n",
    "                for _ in range(self.batch_size):\n",
    "                    img, seg = next(zipped)\n",
    "                    img = cv2.resize(cv2.imread(img, 1), (self.input_width, self.input_height)) / 255.0\n",
    "                    seg = tf.keras.utils.to_categorical(cv2.imread(seg, 0), self.num_classes)\n",
    "                    x_eval.append(img)\n",
    "                    y_eval.append(seg)\n",
    " \n",
    "                yield np.array(x_eval), np.array(y_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train your model here\n",
    "Once you defined the model and data generator, you can start training your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15371/3672649565.py:106: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(\n",
      "2024-07-11 15:07:49.137525: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at conv_ops_fused_impl.h:656 : UNKNOWN: CUDNN failed to allocate the scratch space for the runner or to find a working no-scratch runner.\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\nDetected at node 'model_4/conv2d_120/Relu' defined at (most recent call last):\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n      app.start()\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n      res = shell.run_cell(\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\n      result = self._run_cell(\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\n      result = runner(coro)\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_15371/223020445.py\", line 16, in <module>\n      unet.train()\n    File \"/tmp/ipykernel_15371/3672649565.py\", line 106, in train\n      model.fit_generator(\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/keras/engine/training.py\", line 2604, in fit_generator\n      return self.fit(\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/keras/engine/training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/keras/engine/training.py\", line 1023, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/keras/engine/training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/keras/engine/functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/keras/layers/convolutional/base_conv.py\", line 314, in call\n      return self.activation(outputs)\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/keras/activations.py\", line 317, in relu\n      return backend.relu(\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/keras/backend.py\", line 5369, in relu\n      x = tf.nn.relu(x)\nNode: 'model_4/conv2d_120/Relu'\nCUDNN failed to allocate the scratch space for the runner or to find a working no-scratch runner.\n\t [[{{node model_4/conv2d_120/Relu}}]] [Op:__inference_train_function_22851]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 16\u001b[0m\n\u001b[1;32m      1\u001b[0m unet \u001b[38;5;241m=\u001b[39m UNet(\n\u001b[1;32m      2\u001b[0m     input_width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m572\u001b[39m,\n\u001b[1;32m      3\u001b[0m     input_height\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m572\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     save_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel.h5\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     14\u001b[0m )\n\u001b[0;32m---> 16\u001b[0m \u001b[43munet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 106\u001b[0m, in \u001b[0;36mUNet.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBuilt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    101\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m    102\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_decay),\n\u001b[1;32m    103\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    104\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    105\u001b[0m )\n\u001b[0;32m--> 106\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_generator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mG_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mG_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_path)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/keras/engine/training.py:2604\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2592\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[1;32m   2593\u001b[0m \n\u001b[1;32m   2594\u001b[0m \u001b[38;5;124;03mDEPRECATED:\u001b[39;00m\n\u001b[1;32m   2595\u001b[0m \u001b[38;5;124;03m  `Model.fit` now supports generators, so there is no longer any need to\u001b[39;00m\n\u001b[1;32m   2596\u001b[0m \u001b[38;5;124;03m  use this endpoint.\u001b[39;00m\n\u001b[1;32m   2597\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2598\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   2599\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Model.fit_generator` is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2600\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future version. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2601\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2602\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   2603\u001b[0m )\n\u001b[0;32m-> 2604\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2605\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2606\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2607\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2608\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2609\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2611\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2612\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2613\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2615\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2616\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2617\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2618\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2619\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mUnknownError\u001b[0m: Graph execution error:\n\nDetected at node 'model_4/conv2d_120/Relu' defined at (most recent call last):\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n      app.start()\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n      res = shell.run_cell(\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\n      result = self._run_cell(\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\n      result = runner(coro)\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_15371/223020445.py\", line 16, in <module>\n      unet.train()\n    File \"/tmp/ipykernel_15371/3672649565.py\", line 106, in train\n      model.fit_generator(\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/keras/engine/training.py\", line 2604, in fit_generator\n      return self.fit(\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/keras/engine/training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/keras/engine/training.py\", line 1023, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/keras/engine/training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/keras/engine/functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/keras/layers/convolutional/base_conv.py\", line 314, in call\n      return self.activation(outputs)\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/keras/activations.py\", line 317, in relu\n      return backend.relu(\n    File \"/home/terence/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/keras/backend.py\", line 5369, in relu\n      x = tf.nn.relu(x)\nNode: 'model_4/conv2d_120/Relu'\nCUDNN failed to allocate the scratch space for the runner or to find a working no-scratch runner.\n\t [[{{node model_4/conv2d_120/Relu}}]] [Op:__inference_train_function_22851]"
     ]
    }
   ],
   "source": [
    "unet = UNet(\n",
    "    input_width=572,\n",
    "    input_height=572,\n",
    "    num_classes=3,\n",
    "    train_images='./Train/image/',\n",
    "    train_instances='./Train/masks/',\n",
    "    val_images='./Val/image/',\n",
    "    val_instances='./Val/masks/',\n",
    "    epochs=100,\n",
    "    lr=0.0001,\n",
    "    lr_decay=0.00001,\n",
    "    batch_size=8,\n",
    "    save_path='model.h5'\n",
    ")\n",
    "\n",
    "unet.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model\n",
    "Once your model is trained, remember to save it for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the model on the test set\n",
    "After your last Q&A session, you will be given the test set. Run your model on the test set to get the segmentation results and submit your results in a .zip file. If the MRI image is named '100_fla.nii.gz', save your segmentation result as '100_seg.nii.gz'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
